# lightning.pytorch==2.4.0
seed_everything: 42
trainer:
  accelerator: auto
  strategy:
    class_path: lightning.pytorch.strategies.FSDPStrategy
    init_args:
      auto_wrap_policy:
      - modelgenerator.huggingface_models.fm4bio.modeling_fm4bio.FM4BioLayer
      sharding_strategy: HYBRID_SHARD
  devices: auto
  num_nodes: 1
  precision: 32
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      name: cp_AIDO.Protein_16B
      save_dir: logs
      project: xtrimo_benchmark
  callbacks:
  - class_path: lightning.pytorch.callbacks.ModelCheckpoint
    init_args:
      dirpath: logs/xtrimo_benchmark/cp_AIDO.Protein_16B
      filename: best_val:{epoch}-{val_top_L5_acc:.3f}
      monitor: val_top_L5_acc
      save_top_k: 1
      mode: max
      every_n_epochs: 1
  max_epochs: 20
  max_steps: -1
  log_every_n_steps: 50
  accumulate_grad_batches: 1
  gradient_clip_val: 0.001
  gradient_clip_algorithm: value
  default_root_dir: null
model:
  class_path: modelgenerator.tasks.PairwiseTokenClassification
  init_args:
    adapter:
      class_path: modelgenerator.adapters.MLPAdapter
      init_args:
        hidden_sizes:
        - 128
        activation_layer:
          class_path: torch.nn.ReLU
        bias: true
        dropout: 0
        dropout_in_middle: false
    backbone:
      class_path: modelgenerator.backbones.aido_protein_16b
      init_args:
        max_length: 512
        use_peft: true
        save_peft_only: true
        lora_r: 16
        lora_alpha: 16
        lora_dropout: 0.0
        lora_target_modules:
        - query
        - value
        - key
        - dense
        - router
        lora_use_rslora: true
        config_overwrites:
          hidden_dropout_prob: 0
          attention_probs_dropout_prob: 0
        model_init_args: null
    n_classes: 2
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.0002
        betas:
        - 0.9
        - 0.95
        eps: 1.0e-08
        weight_decay: 0.01
    lr_scheduler:
      class_path: modelgenerator.lr_schedulers.ConstantWithWarmup
      init_args:
        warmup_ratio: 0
    strict_loading: true
    reset_optimizer_states: false
data:
  class_path: modelgenerator.data.ContactPredictionBinary
  init_args:
    path: proteinglm/contact_prediction_binary
    batch_size: 1
    max_length: 512
    train_split_name: train
    test_split_name: test
    valid_split_name: valid
    random_seed: 42
    shuffle: true
ckpt_path: null